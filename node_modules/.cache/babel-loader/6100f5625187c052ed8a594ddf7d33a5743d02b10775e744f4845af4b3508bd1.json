{"ast":null,"code":"'use strict';\n\nconst util = require('util');\nconst crypto = require('crypto');\nconst fs = require('fs');\nconst Minipass = require('minipass');\nconst path = require('path');\nconst ssri = require('ssri');\nconst uniqueFilename = require('unique-filename');\nconst {\n  disposer\n} = require('./util/disposer');\nconst contentPath = require('./content/path');\nconst fixOwner = require('./util/fix-owner');\nconst hashToSegments = require('./util/hash-to-segments');\nconst indexV = require('../package.json')['cache-version'].index;\nconst moveFile = require('@npmcli/move-file');\nconst _rimraf = require('rimraf');\nconst rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nconst appendFile = util.promisify(fs.appendFile);\nconst readFile = util.promisify(fs.readFile);\nconst readdir = util.promisify(fs.readdir);\nconst writeFile = util.promisify(fs.writeFile);\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n};\nmodule.exports.compact = compact;\nasync function compact(cache, key, matchFn) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const bucket = bucketPath(cache, key);\n  const entries = await bucketEntries(bucket);\n  const newEntries = [];\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i];\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry) break;\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(oldEntry => matchFn(oldEntry, entry)))) newEntries.unshift(entry);\n  }\n  const newIndex = '\\n' + newEntries.map(entry => {\n    const stringified = JSON.stringify(entry);\n    const hash = hashEntry(stringified);\n    return `${hash}\\t${stringified}`;\n  }).join('\\n');\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n    await fixOwner.mkdirfix(cache, path.dirname(target));\n    return {\n      target,\n      moved: false\n    };\n  };\n  const teardown = async tmp => {\n    if (!tmp.moved) return rimraf(tmp.target);\n  };\n  const write = async tmp => {\n    await writeFile(tmp.target, newIndex, {\n      flag: 'wx'\n    });\n    await fixOwner.mkdirfix(cache, path.dirname(bucket));\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket);\n    tmp.moved = true;\n    try {\n      await fixOwner.chownr(cache, bucket);\n    } catch (err) {\n      if (err.code !== 'ENOENT') throw err;\n    }\n  };\n\n  // write the file atomically\n  await disposer(setup(), teardown, write);\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map(entry => formatEntry(cache, entry, true));\n}\nmodule.exports.insert = insert;\nfunction insert(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(() => {\n    const stringified = JSON.stringify(entry);\n    // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n    return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  }).then(() => fixOwner.chownr(cache, bucket)).catch(err => {\n    if (err.code === 'ENOENT') return undefined;\n    throw err;\n    // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(() => {\n    return formatEntry(cache, entry);\n  });\n}\nmodule.exports.insert.sync = insertSync;\nfunction insertSync(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') throw err;\n  }\n  return formatEntry(cache, entry);\n}\nmodule.exports.find = find;\nfunction find(cache, key) {\n  const bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(entries => {\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  }).catch(err => {\n    if (err.code === 'ENOENT') return null;else throw err;\n  });\n}\nmodule.exports.find.sync = findSync;\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') return null;else throw err;\n  }\n}\nmodule.exports.delete = del;\nfunction del(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insert(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\nmodule.exports.delete.sync = delSync;\nfunction delSync(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insertSync(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\nmodule.exports.lsStream = lsStream;\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  });\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(buckets.map(bucket => {\n    const bucketPath = path.join(indexDir, bucket);\n    return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(subbuckets.map(subbucket => {\n      const subbucketPath = path.join(bucketPath, subbucket);\n\n      // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n      return readdirOrEmpty(subbucketPath).then(entries => Promise.all(entries.map(entry => {\n        const entryPath = path.join(subbucketPath, entry);\n        return bucketEntries(entryPath).then(entries =>\n        // using a Map here prevents duplicate keys from\n        // showing up twice, I guess?\n        entries.reduce((acc, entry) => {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map())).then(reduced => {\n          // reduced is a map of key => entry\n          for (const entry of reduced.values()) {\n            const formatted = formatEntry(cache, entry);\n            if (formatted) stream.write(formatted);\n          }\n        }).catch(err => {\n          if (err.code === 'ENOENT') return undefined;\n          throw err;\n        });\n      })));\n    })));\n  }))).then(() => stream.end(), err => stream.emit('error', err));\n  return stream;\n}\nmodule.exports.ls = ls;\nfunction ls(cache) {\n  return lsStream(cache).collect().then(entries => entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {}));\n}\nmodule.exports.bucketEntries = bucketEntries;\nfunction bucketEntries(bucket, filter) {\n  return readFile(bucket, 'utf8').then(data => _bucketEntries(data, filter));\n}\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) return;\n    const pieces = entry.split('\\t');\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n    let obj;\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n    if (obj) entries.push(obj);\n  });\n  return entries;\n}\nmodule.exports.bucketDir = bucketDir;\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\nmodule.exports.bucketPath = bucketPath;\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\nmodule.exports.hashKey = hashKey;\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\nmodule.exports.hashEntry = hashEntry;\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) return null;\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\nfunction readdirOrEmpty(dir) {\n  return readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return [];\n    throw err;\n  });\n}","map":{"version":3,"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","disposer","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","appendFile","readFile","readdir","writeFile","module","exports","NotFoundError","Error","constructor","cache","key","code","compact","matchFn","opts","bucket","bucketPath","entries","bucketEntries","newEntries","i","length","entry","integrity","validateEntry","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","flag","chownr","err","reverse","formatEntry","insert","metadata","size","time","Date","now","then","catch","undefined","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","readdirOrEmpty","buckets","Promise","all","subbuckets","subbucket","subbucketPath","entryPath","acc","set","Map","reduced","values","formatted","end","emit","ls","collect","xs","filter","data","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir"],"sources":["/Users/alexmihalascu/Desktop/mpdb-app/node_modules/cacache/lib/entry-index.js"],"sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst { disposer } = require('./util/disposer')\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nconst appendFile = util.promisify(fs.appendFile)\nconst readFile = util.promisify(fs.readFile)\nconst readdir = util.promisify(fs.readdir)\nconst writeFile = util.promisify(fs.writeFile)\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry)\n      break\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry))))\n      newEntries.unshift(entry)\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved)\n      return rimraf(tmp.target)\n  }\n\n  const write = async (tmp) => {\n    await writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT')\n        throw err\n    }\n  }\n\n  // write the file atomically\n  await disposer(setup(), teardown, write)\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nfunction insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  return fixOwner\n    .mkdirfix(cache, path.dirname(bucket))\n    .then(() => {\n      const stringified = JSON.stringify(entry)\n      // NOTE - Cleverness ahoy!\n      //\n      // This works because it's tremendously unlikely for an entry to corrupt\n      // another while still preserving the string length of the JSON in\n      // question. So, we just slap the length in there and verify it on read.\n      //\n      // Thanks to @isaacs for the whiteboarding session that ended up with\n      // this.\n      return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    })\n    .then(() => fixOwner.chownr(cache, bucket))\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return undefined\n\n      throw err\n      // There's a class of race conditions that happen when things get deleted\n      // during fixOwner, or between the two mkdirfix/chownr calls.\n      //\n      // It's perfectly fine to just not bother in those cases and lie\n      // that the index entry was written. Because it's a cache.\n    })\n    .then(() => {\n      return formatEntry(cache, entry)\n    })\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT')\n      throw err\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nfunction find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  return bucketEntries(bucket)\n    .then((entries) => {\n      return entries.reduce((latest, next) => {\n        if (next && next.key === key)\n          return formatEntry(cache, next)\n        else\n          return latest\n      }, null)\n    })\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return null\n      else\n        throw err\n    })\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key)\n        return formatEntry(cache, next)\n      else\n        return latest\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT')\n      return null\n    else\n      throw err\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insert(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insertSync(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(\n    buckets.map(bucket => {\n      const bucketPath = path.join(indexDir, bucket)\n      return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(\n        subbuckets.map(subbucket => {\n          const subbucketPath = path.join(bucketPath, subbucket)\n\n          // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n          return readdirOrEmpty(subbucketPath).then(entries => Promise.all(\n            entries.map(entry => {\n              const entryPath = path.join(subbucketPath, entry)\n              return bucketEntries(entryPath).then(entries =>\n                // using a Map here prevents duplicate keys from\n                // showing up twice, I guess?\n                entries.reduce((acc, entry) => {\n                  acc.set(entry.key, entry)\n                  return acc\n                }, new Map())\n              ).then(reduced => {\n                // reduced is a map of key => entry\n                for (const entry of reduced.values()) {\n                  const formatted = formatEntry(cache, entry)\n                  if (formatted)\n                    stream.write(formatted)\n                }\n              }).catch(err => {\n                if (err.code === 'ENOENT')\n                  return undefined\n                throw err\n              })\n            })\n          ))\n        })\n      ))\n    })\n  ))\n    .then(\n      () => stream.end(),\n      err => stream.emit('error', err)\n    )\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nfunction ls (cache) {\n  return lsStream(cache).collect().then(entries =>\n    entries.reduce((acc, xs) => {\n      acc[xs.key] = xs\n      return acc\n    }, {})\n  )\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nfunction bucketEntries (bucket, filter) {\n  return readFile(bucket, 'utf8').then((data) => _bucketEntries(data, filter))\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry)\n      return\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj)\n      entries.push(obj)\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll)\n    return null\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR')\n      return []\n\n    throw err\n  })\n}\n"],"mappings":"AAAA,YAAY;;AAEZ,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAQ,CAAC;AAChC,MAAME,EAAE,GAAGF,OAAO,CAAC,IAAI,CAAC;AACxB,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAU,CAAC;AACpC,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAiB,CAAC;AAEjD,MAAM;EAAEO;AAAS,CAAC,GAAGP,OAAO,CAAC,iBAAiB,CAAC;AAC/C,MAAMQ,WAAW,GAAGR,OAAO,CAAC,gBAAgB,CAAC;AAC7C,MAAMS,QAAQ,GAAGT,OAAO,CAAC,kBAAkB,CAAC;AAC5C,MAAMU,cAAc,GAAGV,OAAO,CAAC,yBAAyB,CAAC;AACzD,MAAMW,MAAM,GAAGX,OAAO,CAAC,iBAAiB,CAAC,CAAC,eAAe,CAAC,CAACY,KAAK;AAChE,MAAMC,QAAQ,GAAGb,OAAO,CAAC,mBAAmB,CAAC;AAC7C,MAAMc,OAAO,GAAGd,OAAO,CAAC,QAAQ,CAAC;AACjC,MAAMe,MAAM,GAAGhB,IAAI,CAACiB,SAAS,CAACF,OAAO,CAAC;AACtCC,MAAM,CAACE,IAAI,GAAGH,OAAO,CAACG,IAAI;AAE1B,MAAMC,UAAU,GAAGnB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACgB,UAAU,CAAC;AAChD,MAAMC,QAAQ,GAAGpB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACiB,QAAQ,CAAC;AAC5C,MAAMC,OAAO,GAAGrB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACkB,OAAO,CAAC;AAC1C,MAAMC,SAAS,GAAGtB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACmB,SAAS,CAAC;AAE9CC,MAAM,CAACC,OAAO,CAACC,aAAa,GAAG,MAAMA,aAAa,SAASC,KAAK,CAAC;EAC/DC,WAAW,CAAEC,KAAK,EAAEC,GAAG,EAAE;IACvB,KAAK,CAAE,sBAAqBA,GAAI,aAAYD,KAAM,EAAC,CAAC;IACpD,IAAI,CAACE,IAAI,GAAG,QAAQ;IACpB,IAAI,CAACF,KAAK,GAAGA,KAAK;IAClB,IAAI,CAACC,GAAG,GAAGA,GAAG;EAChB;AACF,CAAC;AAEDN,MAAM,CAACC,OAAO,CAACO,OAAO,GAAGA,OAAO;AAEhC,eAAeA,OAAO,CAAEH,KAAK,EAAEC,GAAG,EAAEG,OAAO,EAAa;EAAA,IAAXC,IAAI,uEAAG,CAAC,CAAC;EACpD,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMO,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAM,CAAC;EAC3C,MAAMI,UAAU,GAAG,EAAE;EACrB;EACA;EACA,KAAK,IAAIC,CAAC,GAAGH,OAAO,CAACI,MAAM,GAAG,CAAC,EAAED,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;IAC5C,MAAME,KAAK,GAAGL,OAAO,CAACG,CAAC,CAAC;IACxB;IACA;IACA;IACA;IACA;IACA;IACA;IACA,IAAIE,KAAK,CAACC,SAAS,KAAK,IAAI,IAAI,CAACT,IAAI,CAACU,aAAa,EACjD;;IAEF;IACA;IACA;IACA;IACA,IAAI,CAAC,CAACV,IAAI,CAACU,aAAa,IAAIV,IAAI,CAACU,aAAa,CAACF,KAAK,CAAC,KAAK,IAAI,MAC3DH,UAAU,CAACE,MAAM,KAAK,CAAC,IACtB,CAACF,UAAU,CAACM,IAAI,CAAEC,QAAQ,IAAKb,OAAO,CAACa,QAAQ,EAAEJ,KAAK,CAAC,CAAC,CAAC,EAC3DH,UAAU,CAACQ,OAAO,CAACL,KAAK,CAAC;EAC7B;EAEA,MAAMM,QAAQ,GAAG,IAAI,GAAGT,UAAU,CAACU,GAAG,CAAEP,KAAK,IAAK;IAChD,MAAMQ,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC,MAAMW,IAAI,GAAGC,SAAS,CAACJ,WAAW,CAAC;IACnC,OAAQ,GAAEG,IAAK,KAAIH,WAAY,EAAC;EAClC,CAAC,CAAC,CAACK,IAAI,CAAC,IAAI,CAAC;EAEb,MAAMC,KAAK,GAAG,YAAY;IACxB,MAAMC,MAAM,GAAGjD,cAAc,CAACF,IAAI,CAACiD,IAAI,CAAC1B,KAAK,EAAE,KAAK,CAAC,EAAEK,IAAI,CAACwB,SAAS,CAAC;IACtE,MAAM/C,QAAQ,CAACgD,QAAQ,CAAC9B,KAAK,EAAEvB,IAAI,CAACsD,OAAO,CAACH,MAAM,CAAC,CAAC;IACpD,OAAO;MACLA,MAAM;MACNI,KAAK,EAAE;IACT,CAAC;EACH,CAAC;EAED,MAAMC,QAAQ,GAAG,MAAOC,GAAG,IAAK;IAC9B,IAAI,CAACA,GAAG,CAACF,KAAK,EACZ,OAAO5C,MAAM,CAAC8C,GAAG,CAACN,MAAM,CAAC;EAC7B,CAAC;EAED,MAAMO,KAAK,GAAG,MAAOD,GAAG,IAAK;IAC3B,MAAMxC,SAAS,CAACwC,GAAG,CAACN,MAAM,EAAET,QAAQ,EAAE;MAAEiB,IAAI,EAAE;IAAK,CAAC,CAAC;IACrD,MAAMtD,QAAQ,CAACgD,QAAQ,CAAC9B,KAAK,EAAEvB,IAAI,CAACsD,OAAO,CAACzB,MAAM,CAAC,CAAC;IACpD;IACA;IACA,MAAMpB,QAAQ,CAACgD,GAAG,CAACN,MAAM,EAAEtB,MAAM,CAAC;IAClC4B,GAAG,CAACF,KAAK,GAAG,IAAI;IAChB,IAAI;MACF,MAAMlD,QAAQ,CAACuD,MAAM,CAACrC,KAAK,EAAEM,MAAM,CAAC;IACtC,CAAC,CAAC,OAAOgC,GAAG,EAAE;MACZ,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,MAAMoC,GAAG;IACb;EACF,CAAC;;EAED;EACA,MAAM1D,QAAQ,CAAC+C,KAAK,EAAE,EAAEM,QAAQ,EAAEE,KAAK,CAAC;;EAExC;EACA;EACA;EACA;EACA;EACA,OAAOzB,UAAU,CAAC6B,OAAO,EAAE,CAACnB,GAAG,CAAEP,KAAK,IAAK2B,WAAW,CAACxC,KAAK,EAAEa,KAAK,EAAE,IAAI,CAAC,CAAC;AAC7E;AAEAlB,MAAM,CAACC,OAAO,CAAC6C,MAAM,GAAGA,MAAM;AAE9B,SAASA,MAAM,CAAEzC,KAAK,EAAEC,GAAG,EAAEa,SAAS,EAAa;EAAA,IAAXT,IAAI,uEAAG,CAAC,CAAC;EAC/C,MAAM;IAAEqC,QAAQ;IAAEC;EAAK,CAAC,GAAGtC,IAAI;EAC/B,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMY,KAAK,GAAG;IACZZ,GAAG;IACHa,SAAS,EAAEA,SAAS,IAAIpC,IAAI,CAAC6C,SAAS,CAACT,SAAS,CAAC;IACjD8B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACD,OAAO5D,QAAQ,CACZgD,QAAQ,CAAC9B,KAAK,EAAEvB,IAAI,CAACsD,OAAO,CAACzB,MAAM,CAAC,CAAC,CACrCyC,IAAI,CAAC,MAAM;IACV,MAAM1B,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,OAAOtB,UAAU,CAACe,MAAM,EAAG,KAAImB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;EAC1E,CAAC,CAAC,CACD0B,IAAI,CAAC,MAAMjE,QAAQ,CAACuD,MAAM,CAACrC,KAAK,EAAEM,MAAM,CAAC,CAAC,CAC1C0C,KAAK,CAAEV,GAAG,IAAK;IACd,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,OAAO+C,SAAS;IAElB,MAAMX,GAAG;IACT;IACA;IACA;IACA;IACA;EACF,CAAC,CAAC,CACDS,IAAI,CAAC,MAAM;IACV,OAAOP,WAAW,CAACxC,KAAK,EAAEa,KAAK,CAAC;EAClC,CAAC,CAAC;AACN;AAEAlB,MAAM,CAACC,OAAO,CAAC6C,MAAM,CAACnD,IAAI,GAAG4D,UAAU;AAEvC,SAASA,UAAU,CAAElD,KAAK,EAAEC,GAAG,EAAEa,SAAS,EAAa;EAAA,IAAXT,IAAI,uEAAG,CAAC,CAAC;EACnD,MAAM;IAAEqC,QAAQ;IAAEC;EAAK,CAAC,GAAGtC,IAAI;EAC/B,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMY,KAAK,GAAG;IACZZ,GAAG;IACHa,SAAS,EAAEA,SAAS,IAAIpC,IAAI,CAAC6C,SAAS,CAACT,SAAS,CAAC;IACjD8B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACD5D,QAAQ,CAACgD,QAAQ,CAACxC,IAAI,CAACU,KAAK,EAAEvB,IAAI,CAACsD,OAAO,CAACzB,MAAM,CAAC,CAAC;EACnD,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;EACzCtC,EAAE,CAAC4E,cAAc,CAAC7C,MAAM,EAAG,KAAImB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;EACxE,IAAI;IACFvC,QAAQ,CAACuD,MAAM,CAAC/C,IAAI,CAACU,KAAK,EAAEM,MAAM,CAAC;EACrC,CAAC,CAAC,OAAOgC,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,MAAMoC,GAAG;EACb;EACA,OAAOE,WAAW,CAACxC,KAAK,EAAEa,KAAK,CAAC;AAClC;AAEAlB,MAAM,CAACC,OAAO,CAACoB,IAAI,GAAGA,IAAI;AAE1B,SAASA,IAAI,CAAEhB,KAAK,EAAEC,GAAG,EAAE;EACzB,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOQ,aAAa,CAACH,MAAM,CAAC,CACzByC,IAAI,CAAEvC,OAAO,IAAK;IACjB,OAAOA,OAAO,CAAC4C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACtC,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAG,KAAKA,GAAG,EAC1B,OAAOuC,WAAW,CAACxC,KAAK,EAAEsD,IAAI,CAAC,MAE/B,OAAOD,MAAM;IACjB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,CACDL,KAAK,CAAEV,GAAG,IAAK;IACd,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,OAAO,IAAI,MAEX,MAAMoC,GAAG;EACb,CAAC,CAAC;AACN;AAEA3C,MAAM,CAACC,OAAO,CAACoB,IAAI,CAAC1B,IAAI,GAAGiE,QAAQ;AAEnC,SAASA,QAAQ,CAAEvD,KAAK,EAAEC,GAAG,EAAE;EAC7B,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,IAAI;IACF,OAAOuD,iBAAiB,CAAClD,MAAM,CAAC,CAAC8C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACxD,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAG,KAAKA,GAAG,EAC1B,OAAOuC,WAAW,CAACxC,KAAK,EAAEsD,IAAI,CAAC,MAE/B,OAAOD,MAAM;IACjB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,OAAOf,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,OAAO,IAAI,MAEX,MAAMoC,GAAG;EACb;AACF;AAEA3C,MAAM,CAACC,OAAO,CAAC6D,MAAM,GAAGC,GAAG;AAE3B,SAASA,GAAG,CAAE1D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,uEAAG,CAAC,CAAC;EACjC,IAAI,CAACA,IAAI,CAACsD,WAAW,EACnB,OAAOlB,MAAM,CAACzC,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EAEvC,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOb,MAAM,CAACkB,MAAM,CAAC;AACvB;AAEAX,MAAM,CAACC,OAAO,CAAC6D,MAAM,CAACnE,IAAI,GAAGsE,OAAO;AAEpC,SAASA,OAAO,CAAE5D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,uEAAG,CAAC,CAAC;EACrC,IAAI,CAACA,IAAI,CAACsD,WAAW,EACnB,OAAOT,UAAU,CAAClD,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EAE3C,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOb,MAAM,CAACE,IAAI,CAACgB,MAAM,CAAC;AAC5B;AAEAX,MAAM,CAACC,OAAO,CAACiE,QAAQ,GAAGA,QAAQ;AAElC,SAASA,QAAQ,CAAE7D,KAAK,EAAE;EACxB,MAAM8D,QAAQ,GAAGC,SAAS,CAAC/D,KAAK,CAAC;EACjC,MAAMgE,MAAM,GAAG,IAAIxF,QAAQ,CAAC;IAAEyF,UAAU,EAAE;EAAK,CAAC,CAAC;EAEjDC,cAAc,CAACJ,QAAQ,CAAC,CAACf,IAAI,CAACoB,OAAO,IAAIC,OAAO,CAACC,GAAG,CAClDF,OAAO,CAAC/C,GAAG,CAACd,MAAM,IAAI;IACpB,MAAMC,UAAU,GAAG9B,IAAI,CAACiD,IAAI,CAACoC,QAAQ,EAAExD,MAAM,CAAC;IAC9C,OAAO4D,cAAc,CAAC3D,UAAU,CAAC,CAACwC,IAAI,CAACuB,UAAU,IAAIF,OAAO,CAACC,GAAG,CAC9DC,UAAU,CAAClD,GAAG,CAACmD,SAAS,IAAI;MAC1B,MAAMC,aAAa,GAAG/F,IAAI,CAACiD,IAAI,CAACnB,UAAU,EAAEgE,SAAS,CAAC;;MAEtD;MACA,OAAOL,cAAc,CAACM,aAAa,CAAC,CAACzB,IAAI,CAACvC,OAAO,IAAI4D,OAAO,CAACC,GAAG,CAC9D7D,OAAO,CAACY,GAAG,CAACP,KAAK,IAAI;QACnB,MAAM4D,SAAS,GAAGhG,IAAI,CAACiD,IAAI,CAAC8C,aAAa,EAAE3D,KAAK,CAAC;QACjD,OAAOJ,aAAa,CAACgE,SAAS,CAAC,CAAC1B,IAAI,CAACvC,OAAO;QAC1C;QACA;QACAA,OAAO,CAAC4C,MAAM,CAAC,CAACsB,GAAG,EAAE7D,KAAK,KAAK;UAC7B6D,GAAG,CAACC,GAAG,CAAC9D,KAAK,CAACZ,GAAG,EAAEY,KAAK,CAAC;UACzB,OAAO6D,GAAG;QACZ,CAAC,EAAE,IAAIE,GAAG,EAAE,CAAC,CACd,CAAC7B,IAAI,CAAC8B,OAAO,IAAI;UAChB;UACA,KAAK,MAAMhE,KAAK,IAAIgE,OAAO,CAACC,MAAM,EAAE,EAAE;YACpC,MAAMC,SAAS,GAAGvC,WAAW,CAACxC,KAAK,EAAEa,KAAK,CAAC;YAC3C,IAAIkE,SAAS,EACXf,MAAM,CAAC7B,KAAK,CAAC4C,SAAS,CAAC;UAC3B;QACF,CAAC,CAAC,CAAC/B,KAAK,CAACV,GAAG,IAAI;UACd,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,EACvB,OAAO+C,SAAS;UAClB,MAAMX,GAAG;QACX,CAAC,CAAC;MACJ,CAAC,CAAC,CACH,CAAC;IACJ,CAAC,CAAC,CACH,CAAC;EACJ,CAAC,CAAC,CACH,CAAC,CACCS,IAAI,CACH,MAAMiB,MAAM,CAACgB,GAAG,EAAE,EAClB1C,GAAG,IAAI0B,MAAM,CAACiB,IAAI,CAAC,OAAO,EAAE3C,GAAG,CAAC,CACjC;EAEH,OAAO0B,MAAM;AACf;AAEArE,MAAM,CAACC,OAAO,CAACsF,EAAE,GAAGA,EAAE;AAEtB,SAASA,EAAE,CAAElF,KAAK,EAAE;EAClB,OAAO6D,QAAQ,CAAC7D,KAAK,CAAC,CAACmF,OAAO,EAAE,CAACpC,IAAI,CAACvC,OAAO,IAC3CA,OAAO,CAAC4C,MAAM,CAAC,CAACsB,GAAG,EAAEU,EAAE,KAAK;IAC1BV,GAAG,CAACU,EAAE,CAACnF,GAAG,CAAC,GAAGmF,EAAE;IAChB,OAAOV,GAAG;EACZ,CAAC,EAAE,CAAC,CAAC,CAAC,CACP;AACH;AAEA/E,MAAM,CAACC,OAAO,CAACa,aAAa,GAAGA,aAAa;AAE5C,SAASA,aAAa,CAAEH,MAAM,EAAE+E,MAAM,EAAE;EACtC,OAAO7F,QAAQ,CAACc,MAAM,EAAE,MAAM,CAAC,CAACyC,IAAI,CAAEuC,IAAI,IAAKC,cAAc,CAACD,IAAI,EAAED,MAAM,CAAC,CAAC;AAC9E;AAEA1F,MAAM,CAACC,OAAO,CAACa,aAAa,CAACnB,IAAI,GAAGkE,iBAAiB;AAErD,SAASA,iBAAiB,CAAElD,MAAM,EAAE+E,MAAM,EAAE;EAC1C,MAAMC,IAAI,GAAG/G,EAAE,CAACiH,YAAY,CAAClF,MAAM,EAAE,MAAM,CAAC;EAC5C,OAAOiF,cAAc,CAACD,IAAI,EAAED,MAAM,CAAC;AACrC;AAEA,SAASE,cAAc,CAAED,IAAI,EAAED,MAAM,EAAE;EACrC,MAAM7E,OAAO,GAAG,EAAE;EAClB8E,IAAI,CAACG,KAAK,CAAC,IAAI,CAAC,CAACC,OAAO,CAAE7E,KAAK,IAAK;IAClC,IAAI,CAACA,KAAK,EACR;IAEF,MAAM8E,MAAM,GAAG9E,KAAK,CAAC4E,KAAK,CAAC,IAAI,CAAC;IAChC,IAAI,CAACE,MAAM,CAAC,CAAC,CAAC,IAAIlE,SAAS,CAACkE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAKA,MAAM,CAAC,CAAC,CAAC,EAAE;MACpD;MACA;MACA;IACF;IACA,IAAIC,GAAG;IACP,IAAI;MACFA,GAAG,GAAGtE,IAAI,CAACuE,KAAK,CAACF,MAAM,CAAC,CAAC,CAAC,CAAC;IAC7B,CAAC,CAAC,OAAOG,CAAC,EAAE;MACV;MACA;IACF;IACA,IAAIF,GAAG,EACLpF,OAAO,CAACuF,IAAI,CAACH,GAAG,CAAC;EACrB,CAAC,CAAC;EACF,OAAOpF,OAAO;AAChB;AAEAb,MAAM,CAACC,OAAO,CAACmE,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAAS,CAAE/D,KAAK,EAAE;EACzB,OAAOvB,IAAI,CAACiD,IAAI,CAAC1B,KAAK,EAAG,UAAShB,MAAO,EAAC,CAAC;AAC7C;AAEAW,MAAM,CAACC,OAAO,CAACW,UAAU,GAAGA,UAAU;AAEtC,SAASA,UAAU,CAAEP,KAAK,EAAEC,GAAG,EAAE;EAC/B,MAAM+F,MAAM,GAAGC,OAAO,CAAChG,GAAG,CAAC;EAC3B,OAAOxB,IAAI,CAACiD,IAAI,CAACwE,KAAK,CACpBzH,IAAI,EACJ,CAACsF,SAAS,CAAC/D,KAAK,CAAC,CAAC,CAACmG,MAAM,CAACpH,cAAc,CAACiH,MAAM,CAAC,CAAC,CAClD;AACH;AAEArG,MAAM,CAACC,OAAO,CAACqG,OAAO,GAAGA,OAAO;AAEhC,SAASA,OAAO,CAAEhG,GAAG,EAAE;EACrB,OAAOuB,IAAI,CAACvB,GAAG,EAAE,QAAQ,CAAC;AAC5B;AAEAN,MAAM,CAACC,OAAO,CAAC6B,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAAS,CAAE2E,GAAG,EAAE;EACvB,OAAO5E,IAAI,CAAC4E,GAAG,EAAE,MAAM,CAAC;AAC1B;AAEA,SAAS5E,IAAI,CAAE4E,GAAG,EAAEC,MAAM,EAAE;EAC1B,OAAO/H,MAAM,CACVgI,UAAU,CAACD,MAAM,CAAC,CAClBE,MAAM,CAACH,GAAG,CAAC,CACXC,MAAM,CAAC,KAAK,CAAC;AAClB;AAEA,SAAS7D,WAAW,CAAExC,KAAK,EAAEa,KAAK,EAAE2F,OAAO,EAAE;EAC3C;EACA,IAAI,CAAC3F,KAAK,CAACC,SAAS,IAAI,CAAC0F,OAAO,EAC9B,OAAO,IAAI;EAEb,OAAO;IACLvG,GAAG,EAAEY,KAAK,CAACZ,GAAG;IACda,SAAS,EAAED,KAAK,CAACC,SAAS;IAC1BrC,IAAI,EAAEoC,KAAK,CAACC,SAAS,GAAGjC,WAAW,CAACmB,KAAK,EAAEa,KAAK,CAACC,SAAS,CAAC,GAAGmC,SAAS;IACvEN,IAAI,EAAE9B,KAAK,CAAC8B,IAAI;IAChBC,IAAI,EAAE/B,KAAK,CAAC+B,IAAI;IAChBF,QAAQ,EAAE7B,KAAK,CAAC6B;EAClB,CAAC;AACH;AAEA,SAASwB,cAAc,CAAEuC,GAAG,EAAE;EAC5B,OAAOhH,OAAO,CAACgH,GAAG,CAAC,CAACzD,KAAK,CAAEV,GAAG,IAAK;IACjC,IAAIA,GAAG,CAACpC,IAAI,KAAK,QAAQ,IAAIoC,GAAG,CAACpC,IAAI,KAAK,SAAS,EACjD,OAAO,EAAE;IAEX,MAAMoC,GAAG;EACX,CAAC,CAAC;AACJ"},"metadata":{},"sourceType":"script","externalDependencies":[]}